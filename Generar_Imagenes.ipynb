{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IOlivaresPalma/LLM-Agents/blob/main/Generar_Imagenes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-groq transformers"
      ],
      "metadata": {
        "id": "DsRwRKZmuOUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoRpRuHtf1cm"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from IPython.display import Markdown, display\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.agents import AgentExecutor\n",
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# We'll be exploring a number of pipelines today!\n",
        "from diffusers import (\n",
        "    StableDiffusionPipeline,\n",
        "    StableDiffusionImg2ImgPipeline,\n",
        "    StableDiffusionInpaintPipeline,\n",
        "    StableDiffusionDepth2ImgPipeline\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se carga el modelo de Stable-difusion"
      ],
      "metadata": {
        "id": "EXGHDaRWucLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "oNtfPd6EuFui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "pUOaRo4qubqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definicion de las Tools"
      ],
      "metadata": {
        "id": "eCq1m4nhwO-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def generador_imagenes(query: str) -> str:\n",
        "  '''Genera, enseña o muestra una imagen dependiendo de la frase que se entregue'''\n",
        "  prompt = query\n",
        "\n",
        "  prompt_template1 = PromptTemplate.from_template(\n",
        "    \"Genera contexto y descripcion para la frase siguiente: '{imagen}'\"\n",
        "  )\n",
        "\n",
        "  context = prompt_template1.format(imagen=prompt)\n",
        "  #print(context)\n",
        "\n",
        "  esp = llm.invoke(context)\n",
        "  print(esp.content)\n",
        "\n",
        "  prompt_template2 = PromptTemplate.from_template(\n",
        "    \"Traduce el siguiente texto del idioma que detectas al ingles: '{frase}'\"\n",
        "  )\n",
        "\n",
        "  espannol = prompt_template2.format(frase=esp.content)\n",
        "  #print(esp)\n",
        "\n",
        "  ingles = llm.invoke(espannol)\n",
        "  print(ing)\n",
        "  image = pipe(ing).images[0]\n",
        "\n",
        "  display(image)\n",
        "  return image\n",
        "\n",
        "generador_imagenes.invoke(\"nave espacial cerca de jupiter\")"
      ],
      "metadata": {
        "id": "TpBClJ6Kvubo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generador_imagenes.invoke(\"pizza en el espacio\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zi57JjXI2I3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instanciar LLM y unir Tool"
      ],
      "metadata": {
        "id": "nSm0GLZ631HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model = \"llama3-groq-70b-8192-tool-use-preview\",\n",
        "    temperature = 0.0\n",
        ")\n",
        "\n",
        "tools = [generador_imagenes]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "LelNZ-_AvizY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama3-groq-70b-8192-tool-use-preview\", api_key=userdata.get('GROQ_API_KEY'),\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "tools = [generador_imagenes]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "q39TO8tC3qka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurar el chatbot para que tenga memoria"
      ],
      "metadata": {
        "id": "FyUbuzn04M0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "from langchain.agents import AgentExecutor, Tool\n",
        "\n",
        "MEMORY_KEY = \"chat_history\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Eres un asistente IA cuyo primer mensaje pregunta el nombre del usuario y avisa la ejecución de alguna herramienta\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat_history=[]\n",
        "\n",
        "\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "    }\n",
        "    | prompt\n",
        "    | llm_with_tools\n",
        "    | OpenAIToolsAgentOutputParser()\n",
        ")\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n"
      ],
      "metadata": {
        "id": "_RljC-8e4MeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correr chatbot"
      ],
      "metadata": {
        "id": "jHNQs_TE4tvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  query = input(\"Usuario: \")\n",
        "  if query.lower() in [\"salir\", \"exit\", \"chao\"]:\n",
        "    break\n",
        "\n",
        "  answer = agent_executor.invoke({\"input\": query, \"chat_history\": chat_history})\n",
        "  chat_history.extend(\n",
        "      [\n",
        "          HumanMessage(content=query),\n",
        "          AIMessage(content=answer[\"output\"]),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  print(f'IA: {answer[\"output\"]}')"
      ],
      "metadata": {
        "id": "9ug0VQvn4QTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"Generar imagen caballo volador\", \"chat_history\": chat_history})"
      ],
      "metadata": {
        "id": "wxYwbea_BAkx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}